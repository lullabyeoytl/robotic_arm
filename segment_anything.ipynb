{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境设置&库与model下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%nvidia-smi` not found.\n"
     ]
    }
   ],
   "source": [
    "%nvidia-smi    #GPU设置\n",
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)\n",
    "%cd {HOME}\n",
    "%git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
    "%cd {HOME}/GroundingDINO\n",
    "%git checkout -q 57535c5a79791cb76e36fdb64975271354f10251#文件的哈希码\n",
    "%pip install -q -e .\n",
    "#Grounding-DINO下载\n",
    "%cd {HOME}\n",
    "import sys\n",
    "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "#segment_anything下载\n",
    "%pip uninstall -y supervision\n",
    "%pip install -q supervision==0.6.0\n",
    "import supervision as sv\n",
    "print(sv.__version__)\n",
    "#supervision\n",
    "%pip install -q roboflow\n",
    "#roboflow\n",
    "\n",
    "#load model\n",
    "%cd {HOME}\n",
    "%mkdir -p {HOME}/weights\n",
    "%cd {HOME}/weights\n",
    "%wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
    "GROUNDING_DINO_CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"groundingdino_swint_ogc.pth\")\n",
    "print(GROUNDING_DINO_CHECKPOINT_PATH, \"; exist:\", os.path.isfile(GROUNDING_DINO_CHECKPOINT_PATH))\n",
    "%cd {HOME}\n",
    "%mkdir -p {HOME}/weights\n",
    "%cd {HOME}/weights\n",
    "%wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "SAM_CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
    "print(SAM_CHECKPOINT_PATH, \"; exist:\", os.path.isfile(SAM_CHECKPOINT_PATH))\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd {HOME}/GroundingDINO\n",
    "from groundingdino.util.inference import Model\n",
    "grounding_dino_model = Model(model_config_path=GROUNDING_DINO_CONFIG_PATH, model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH)\n",
    "SAM_ENCODER_VERSION = \"vit_h\"\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "sam = sam_model_registry[SAM_ENCODER_VERSION](checkpoint=SAM_CHECKPOINT_PATH).to(device=DEVICE)\n",
    "sam_predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文件加载&放置\n",
    "%cd {HOME}\n",
    "%mkdir {HOME}/data\n",
    "%cd {HOME}/data\n",
    "SOURCE_IMAGE_PATH = f\"{HOME}/data_1/out_2.jpg\"#文件地址\n",
    "#CLASSES = ['fresh apple', 'rooted apple']\n",
    "CLASSES=['lemon','orange','pear','strawberry','kiwi fruit']\n",
    "BOX_TRESHOLD = 0.35\n",
    "TEXT_TRESHOLD = 0.25\n",
    "#参数设置\n",
    "\n",
    "import cv2\n",
    "import supervision as sv\n",
    "\n",
    "# load image\n",
    "image = cv2.imread(SOURCE_IMAGE_PATH)\n",
    "\n",
    "# detect objects\n",
    "detections = grounding_dino_model.predict_with_classes(\n",
    "    image=image,\n",
    "    classes=enhance_class_name(class_names=CLASSES),\n",
    "    box_threshold=BOX_TRESHOLD,\n",
    "    text_threshold=TEXT_TRESHOLD\n",
    ")\n",
    "\n",
    "# annotate image with detections\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "labels = [\n",
    "    f\"{CLASSES[class_id]} {confidence:0.2f}\"\n",
    "    for _, _, confidence, class_id, _\n",
    "    in detections]\n",
    "annotated_frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(annotated_frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#边缘分割：\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor\n",
    "\n",
    "\n",
    "def segment(sam_predictor: SamPredictor, image: np.ndarray, xyxy: np.ndarray) -> np.ndarray:\n",
    "    sam_predictor.set_image(image)\n",
    "    result_masks = []\n",
    "    for box in xyxy:\n",
    "        masks, scores, logits = sam_predictor.predict(\n",
    "            box=box,\n",
    "            multimask_output=True\n",
    "        )\n",
    "        index = np.argmax(scores)\n",
    "        result_masks.append(masks[index])\n",
    "    return np.array(result_masks)\n",
    "import cv2\n",
    "\n",
    "#边缘覆盖\n",
    "detections.mask = segment(\n",
    "    sam_predictor=sam_predictor,\n",
    "    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n",
    "    xyxy=detections.xyxy\n",
    ")\n",
    "\n",
    "# 标识检测文件\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "labels = [\n",
    "    f\"{CLASSES[class_id]} {confidence:0.2f}\"\n",
    "    for _, _, confidence, class_id, _\n",
    "    in detections]\n",
    "annotated_image = mask_annotator.annotate(scene=image.copy(), detections=detections)\n",
    "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "path = f\"{HOME}/data_1/\"+'out.jpg'\n",
    "sv.plot_image(annotated_image, (16, 16))\n",
    "cv2.imwrite(path,annotated_image)\n",
    "#生成标识并导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#黑白分割文件\n",
    "import math\n",
    "grid_size_dimension = math.ceil(math.sqrt(len(detections.mask)))\n",
    "titles = [\n",
    "    CLASSES[class_id]\n",
    "    for class_id\n",
    "    in detections.class_id\n",
    "]\n",
    "sv.plot_images_grid(\n",
    "    images=detections.mask,\n",
    "    titles=titles,\n",
    "    grid_size=(grid_size_dimension, grid_size_dimension),\n",
    "    size=(16, 16)\n",
    ")\n",
    "digit=0\n",
    "for image in detections:\n",
    "  title=titles[digit]+str(digit)+'.jpg'\n",
    "  path = f\"{HOME}/data_1/\"+title+str(digit)\n",
    "  cv2.imwrite(path,image)\n",
    "  digit+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多文件同class生成\n",
    "import os\n",
    "\n",
    "IMAGES_DIRECTORY = os.path.join(HOME, 'data_1')\n",
    "IMAGES_EXTENSIONS = ['jpg', 'jpeg', 'png']\n",
    "\n",
    "CLASSES=['lemon','orange','pear','strawberry','kiwi fruit']\n",
    "BOX_TRESHOLD = 0.35\n",
    "TEXT_TRESHOLD = 0.25\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "images = {}\n",
    "annotations = {}\n",
    "\n",
    "image_paths = sv.list_files_with_extensions(\n",
    "    directory=IMAGES_DIRECTORY,\n",
    "    extensions=IMAGES_EXTENSIONS)\n",
    "\n",
    "for image_path in tqdm(image_paths):\n",
    "    image_name = image_path.name\n",
    "    image_path = str(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    detections = grounding_dino_model.predict_with_classes(\n",
    "        image=image,\n",
    "        classes=enhance_class_name(class_names=CLASSES),\n",
    "        box_threshold=BOX_TRESHOLD,\n",
    "        text_threshold=TEXT_TRESHOLD\n",
    "    )\n",
    "    detections = detections[detections.class_id != None]\n",
    "    detections.mask = segment(\n",
    "        sam_predictor=sam_predictor,\n",
    "        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n",
    "        xyxy=detections.xyxy\n",
    "    )\n",
    "    images[image_name] = image\n",
    "    annotations[image_name] = detections\n",
    "\n",
    "plot_images = []\n",
    "plot_titles = []\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "\n",
    "for image_name, detections in annotations.items():\n",
    "    image = images[image_name]\n",
    "    plot_images.append(image)\n",
    "    plot_titles.append(image_name)\n",
    "\n",
    "    labels = [\n",
    "        f\"{CLASSES[class_id]} {confidence:0.2f}\"\n",
    "        for _, _, confidence, class_id, _\n",
    "        in detections]\n",
    "    annotated_image = mask_annotator.annotate(scene=image.copy(), detections=detections)\n",
    "    annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "    plot_images.append(annotated_image)\n",
    "    title = \" \".join(set([\n",
    "        CLASSES[class_id]\n",
    "        for class_id\n",
    "        in detections.class_id\n",
    "    ]))\n",
    "    plot_titles.append(title)\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=plot_images,\n",
    "    titles=plot_titles,\n",
    "    grid_size=(len(annotations), 2),\n",
    "    size=(2 * 4, len(annotations) * 4)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
