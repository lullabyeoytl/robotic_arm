{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境设置&库与model下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME: d:\\oytl\\university\\robotic_arm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'GroundingDINO'...\n",
      "fatal: unable to access 'https://github.com/IDEA-Research/GroundingDINO.git/': Failure when receiving data from the peer\n",
      "ϵͳ�Ҳ���ָ����·����\n",
      "fatal: reference is not a tree: 57535c5a79791cb76e36fdb64975271354f10251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: file:///D:/oytl/university/robotic_arm does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi    #GPU设置\n",
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)\n",
    "!cd {HOME}\n",
    "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
    "!cd {HOME}/GroundingDINO\n",
    "!git checkout -q 57535c5a79791cb76e36fdb64975271354f10251 #文件的哈希码\n",
    "%pip install -q -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\oytl\\university\\robotic_arm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oytl1027\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n",
      "ERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/segment-anything.git'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: supervision 0.6.0\n",
      "Uninstalling supervision-0.6.0:\n",
      "  Successfully uninstalled supervision-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "import sys\n",
    "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "#segment_anything下载\n",
    "%pip uninstall -y supervision\n",
    "%pip install -q supervision==0.6.0\n",
    "import supervision as sv\n",
    "print(sv.__version__)\n",
    "#supervision\n",
    "%pip install -q roboflow\n",
    "#roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "%cd {HOME}\n",
    "%mkdir -p {HOME}/weights\n",
    "%cd {HOME}/weights\n",
    "%wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
    "GROUNDING_DINO_CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"groundingdino_swint_ogc.pth\")\n",
    "print(GROUNDING_DINO_CHECKPOINT_PATH, \"; exist:\", os.path.isfile(GROUNDING_DINO_CHECKPOINT_PATH))\n",
    "%cd {HOME}\n",
    "%mkdir -p {HOME}/weights\n",
    "%cd {HOME}/weights\n",
    "%wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "SAM_CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
    "print(SAM_CHECKPOINT_PATH, \"; exist:\", os.path.isfile(SAM_CHECKPOINT_PATH))\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd {HOME}/GroundingDINO\n",
    "from groundingdino.util.inference import Model\n",
    "grounding_dino_model = Model(model_config_path=GROUNDING_DINO_CONFIG_PATH, model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH)\n",
    "SAM_ENCODER_VERSION = \"vit_h\"\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "sam = sam_model_registry[SAM_ENCODER_VERSION](checkpoint=SAM_CHECKPOINT_PATH).to(device=DEVICE)\n",
    "sam_predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文件加载&放置\n",
    "%cd {HOME}\n",
    "%mkdir {HOME}/data\n",
    "%cd {HOME}/data\n",
    "SOURCE_IMAGE_PATH = f\"{HOME}/data_1/out_2.jpg\"#文件地址\n",
    "#CLASSES = ['fresh apple', 'rooted apple']\n",
    "CLASSES=['lemon','orange','pear','strawberry','kiwi fruit']\n",
    "BOX_TRESHOLD = 0.35\n",
    "TEXT_TRESHOLD = 0.25\n",
    "#参数设置\n",
    "\n",
    "import cv2\n",
    "import supervision as sv\n",
    "\n",
    "# load image\n",
    "image = cv2.imread(SOURCE_IMAGE_PATH)\n",
    "\n",
    "# detect objects\n",
    "detections = grounding_dino_model.predict_with_classes(\n",
    "    image=image,\n",
    "    classes=enhance_class_name(class_names=CLASSES),\n",
    "    box_threshold=BOX_TRESHOLD,\n",
    "    text_threshold=TEXT_TRESHOLD\n",
    ")\n",
    "\n",
    "# annotate image with detections\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "labels = [\n",
    "    f\"{CLASSES[class_id]} {confidence:0.2f}\"\n",
    "    for _, _, confidence, class_id, _\n",
    "    in detections]\n",
    "annotated_frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(annotated_frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#边缘分割：\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor\n",
    "\n",
    "\n",
    "def segment(sam_predictor: SamPredictor, image: np.ndarray, xyxy: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    使用SAM预测器对图像进行分割，返回分割后的掩码数组\n",
    "    \"\"\"\n",
    "    sam_predictor.set_image(image)\n",
    "    result_masks = []\n",
    "    for box in xyxy:\n",
    "        masks, scores, logits = sam_predictor.predict(\n",
    "            box=box,\n",
    "            multimask_output=True\n",
    "        )\n",
    "        index = np.argmax(scores)\n",
    "        result_masks.append(masks[index])\n",
    "    return np.array(result_masks)\n",
    "\n",
    "import cv2\n",
    "\n",
    "#边缘覆盖\n",
    "detections.mask = segment(\n",
    "    sam_predictor=sam_predictor,\n",
    "    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n",
    "    xyxy=detections.xyxy\n",
    ")\n",
    "\n",
    "# 标识检测文件\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "labels = [\n",
    "    f\"{CLASSES[class_id]} {confidence:0.2f}\"\n",
    "    for _, _, confidence, class_id, _\n",
    "    in detections]\n",
    "annotated_image = mask_annotator.annotate(scene=image.copy(), detections=detections)\n",
    "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "path = f\"{HOME}/data_1/\"+'out.jpg'\n",
    "sv.plot_image(annotated_image, (16, 16))\n",
    "cv2.imwrite(path,annotated_image)\n",
    "#生成标识并导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#黑白分割文件\n",
    "import math\n",
    "\n",
    "# 计算网格尺寸的维度\n",
    "grid_size_dimension = math.ceil(math.sqrt(len(detections.mask)))\n",
    "\n",
    "# 生成每个检测对象的标题\n",
    "titles = [\n",
    "    CLASSES[class_id]\n",
    "    for class_id\n",
    "    in detections.class_id\n",
    "]\n",
    "\n",
    "# 绘制图像网格\n",
    "sv.plot_images_grid(\n",
    "    images=detections.mask,\n",
    "    titles=titles,\n",
    "    grid_size=(grid_size_dimension, grid_size_dimension),\n",
    "    size=(16, 16)\n",
    ")\n",
    "\n",
    "# 初始化计数器\n",
    "digit=0\n",
    "\n",
    "# 遍历检测对象并保存图像\n",
    "for image in detections:\n",
    "  title=titles[digit]+str(digit)+'.jpg'\n",
    "  path = f\"{HOME}/data_1/\"+title+str(digit)\n",
    "  cv2.imwrite(path,image)\n",
    "  digit+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多文件同class生成\n",
    "import os\n",
    "\n",
    "IMAGES_DIRECTORY = os.path.join(HOME, 'data_1')\n",
    "IMAGES_EXTENSIONS = ['jpg', 'jpeg', 'png']\n",
    "\n",
    "CLASSES=['lemon','orange','pear','strawberry','kiwi fruit']\n",
    "BOX_TRESHOLD = 0.35\n",
    "TEXT_TRESHOLD = 0.25\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "images = {}\n",
    "annotations = {}\n",
    "\n",
    "image_paths = sv.list_files_with_extensions(\n",
    "    directory=IMAGES_DIRECTORY,\n",
    "    extensions=IMAGES_EXTENSIONS)\n",
    "\n",
    "for image_path in tqdm(image_paths):\n",
    "    image_name = image_path.name\n",
    "    image_path = str(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    detections = grounding_dino_model.predict_with_classes(\n",
    "        image=image,\n",
    "        classes=enhance_class_name(class_names=CLASSES),\n",
    "        box_threshold=BOX_TRESHOLD,\n",
    "        text_threshold=TEXT_TRESHOLD\n",
    "    )\n",
    "    detections = detections[detections.class_id != None]\n",
    "    detections.mask = segment(\n",
    "        sam_predictor=sam_predictor,\n",
    "        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n",
    "        xyxy=detections.xyxy\n",
    "    )\n",
    "    images[image_name] = image\n",
    "    annotations[image_name] = detections\n",
    "\n",
    "plot_images = []\n",
    "plot_titles = []\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "\n",
    "for image_name, detections in annotations.items():\n",
    "    image = images[image_name]\n",
    "    plot_images.append(image)\n",
    "    plot_titles.append(image_name)\n",
    "\n",
    "    labels = [\n",
    "        f\"{CLASSES[class_id]} {confidence:0.2f}\"\n",
    "        for _, _, confidence, class_id, _\n",
    "        in detections]\n",
    "    annotated_image = mask_annotator.annotate(scene=image.copy(), detections=detections)\n",
    "    annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "    plot_images.append(annotated_image)\n",
    "    title = \" \".join(set([\n",
    "        CLASSES[class_id]\n",
    "        for class_id\n",
    "        in detections.class_id\n",
    "    ]))\n",
    "    plot_titles.append(title)\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=plot_images,\n",
    "    titles=plot_titles,\n",
    "    grid_size=(len(annotations), 2),\n",
    "    size=(2 * 4, len(annotations) * 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save labels in Pascal VOC XML\n",
    "\n",
    "Before uploading our annotations to Roboflow, we must first save them to our hard drive. To do this, we will use one of the latest `supervision` features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_DIRECTORY = os.path.join(HOME, 'annotations')\n",
    "\n",
    "MIN_IMAGE_AREA_PERCENTAGE = 0.002\n",
    "MAX_IMAGE_AREA_PERCENTAGE = 0.80\n",
    "APPROXIMATION_PERCENTAGE = 0.75\n",
    "\n",
    "# 定义一个数据集对象，包含类别、图像和注解\n",
    "sv.Dataset(\n",
    "    classes=CLASSES,\n",
    "    images=images,\n",
    "    annotations=annotations\n",
    ").as_pascal_voc(\n",
    "    # 将数据集转换为Pascal VOC格式，并指定注解目录路径\n",
    "    annotations_directory_path=ANNOTATIONS_DIRECTORY,\n",
    "    # 设置最小图像区域百分比\n",
    "    min_image_area_percentage=MIN_IMAGE_AREA_PERCENTAGE,\n",
    "    # 设置最大图像区域百分比\n",
    "    max_image_area_percentage=MAX_IMAGE_AREA_PERCENTAGE,\n",
    "    # 设置近似百分比\n",
    "    approximation_percentage=APPROXIMATION_PERCENTAGE\n",
    ")\n",
    "\n",
    "\n",
    "#upload annotations to roboflow\n",
    "PROJECT_NAME = \"auto-generated-dataset-7\"\n",
    "PROJECT_DESCRIPTION = \"auto-generated-dataset-7\"\n",
    "\n",
    "import roboflow\n",
    "from roboflow import Roboflow\n",
    "\n",
    "roboflow.login()\n",
    "\n",
    "workspace = Roboflow().workspace()\n",
    "new_project = workspace.create_project(\n",
    "    project_name=PROJECT_NAME,\n",
    "    project_license=\"MIT\",\n",
    "    project_type=\"instance-segmentation\",\n",
    "    annotation=PROJECT_DESCRIPTION)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# 遍历图像路径列表，并使用 tqdm 显示进度条\n",
    "for image_path in tqdm(image_paths):\n",
    "    # 获取图像文件名\n",
    "    image_name = image_path.name\n",
    "    # 构造对应的标注文件名\n",
    "    annotation_name = f\"{image_path.stem}.xml\"\n",
    "    # 将图像路径转换为字符串\n",
    "    image_path = str(image_path)\n",
    "    # 构造标注文件的完整路径\n",
    "    annotation_path = os.path.join(ANNOTATIONS_DIRECTORY, annotation_name)\n",
    "    # 上传图像和标注文件到新项目中\n",
    "    new_project.upload(\n",
    "        image_path=image_path,\n",
    "        annotation_path=annotation_path,\n",
    "        split=\"train\",\n",
    "        is_prediction=True,\n",
    "        overwrite=True,\n",
    "        tag_names=[\"auto-annotated-with-grounded-sam\"],\n",
    "        batch_name=\"auto-annotated-with-grounded-sam\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
